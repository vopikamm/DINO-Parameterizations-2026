#!/usr/bin/env bash
######################
## JEANZAY IDRIS ##
######################
#SBATCH --job-name=DINO_GZ21
#SBATCH --output=DINO_GZ21.out
#SBATCH --error=DINO_GZ21.err
#SBATCH --ntasks-per-node=40
#SBATCH --nodes=4
#SBATCH --gres=gpu:4         # Number of GPU per node
#SBATCH --hint=nomultithread # One MPI process per physical core (no hyperthreading)
#SBATCH --time=4:00:00
#SBATCH --qos=qos_gpu-t3 # QoS

# Load Environnment
module purge # purge modules inherited by default

# loading necessary modules
intel_version=19.0.4
module load intel-compilers/${intel_version}
module load intel-mpi/${intel_version}
module load hdf5/1.10.5-mpi
module load netcdf/4.7.2-mpi
module load netcdf-fortran/4.5.2-mpi
module load python/3.10.4

source $I_MPI_ROOT/intel64/bin/mpivars.sh release_mt

# Move to execution directory
cd ${SLURM_SUBMIT_DIR}
cd ./EXP00
set -x
pwd

date

# job information 
cat << EOF
------------------------------------------------------------------
Job submit on $SLURM_SUBMIT_HOST by $SLURM_JOB_USER
JobID=$SLURM_JOBID Running_Node=$SLURM_NODELIST 
Node=$SLURM_JOB_NUM_NODES Task=$SLURM_NTASKS
------------------------------------------------------------------
EOF

# Begin of section with executable commands
set -e
ls -l

# run eophis in preproduction mode to generate namcouple
touch namcouple
rm namcouple*
python3 ./main.py --exec preprod

# save eophis preproduction logs
mv eophis.out eophis_preprod.out
mv eophis.err eophis_preprod.err

# check if preproduction did well generate namcouple
namcouple=namcouple
if [ ! -e ${namcouple} ]; then
        echo "namcouple can not be found, preproduction failed"
        exit 1
else
        echo "preproduction successful"
fi

# run coupled NEMO-Python
time srun --multi-prog ./run_file

date
